{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path  C:/Users/natiami/Downloads/Neuro/Project/traindata/A01TInstances.csv\n",
      "(672528, 25)\n",
      "Path  C:/Users/natiami/Downloads/Neuro/Project/traindata/A02TInstances.csv\n",
      "(1349697, 25)\n",
      "Path  C:/Users/natiami/Downloads/Neuro/Project/traindata/A03TInstances.csv\n",
      "(2010227, 25)\n",
      "Path  C:/Users/natiami/Downloads/Neuro/Project/traindata/A04TInstances.csv\n",
      "(2611142, 25)\n",
      "Path  C:/Users/natiami/Downloads/Neuro/Project/traindata/A05TInstances.csv\n",
      "(3297262, 25)\n",
      "Path  C:/Users/natiami/Downloads/Neuro/Project/traindata/A06TInstances.csv\n",
      "(3976242, 25)\n",
      "Path  C:/Users/natiami/Downloads/Neuro/Project/traindata/A07TInstances.csv\n",
      "(4657313, 25)\n",
      "Path  C:/Users/natiami/Downloads/Neuro/Project/traindata/A08TInstances.csv\n",
      "(5332583, 25)\n",
      "Path  C:/Users/natiami/Downloads/Neuro/Project/traindata/A09TInstances.csv\n",
      "(6005911, 25)\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.DataFrame()\n",
    "labels = pd.DataFrame()\n",
    "#path_file = \"C:/Users/Marielle/Documents/Uni Tartu/Introduction to Computational Neuroscience/traindata/traindata/A01TInstances.csv\"\n",
    "#path_label = \"C:/Users/Marielle/Documents/Uni Tartu/Introduction to Computational Neuroscience/traindata//traindata/A01TLabels.csv\"\n",
    "#path_file = \"C:\\\\kool\\\\sissejuhatus arvutuslikku neuroteadusesse\\\\project\\\\traindata\\\\A01TInstances.csv\"\n",
    "#path_label = \"C:\\\\kool\\\\sissejuhatus arvutuslikku neuroteadusesse\\\\project\\\\traindata\\\\A01TLabels.csv\"\n",
    "path_file = \"C:/Users/natiami/Downloads/Neuro/Project/traindata/A01TInstances.csv\"\n",
    "path_label =\"C:/Users/natiami/Downloads/Neuro/Project/traindata/A01TLabels.csv\"\n",
    "data_list = []\n",
    "\n",
    "for i in range(9):\n",
    "    print(\"Path \", path_file)\n",
    "    \n",
    "    feature = pd.read_csv(path_file, header=None)\n",
    "    dataset = dataset.append(feature)\n",
    "    \n",
    "    \n",
    "    label = pd.read_csv(path_label, header=None)\n",
    "    labels = labels.append(label)\n",
    "    \n",
    "    data_list.append([feature, label]) \n",
    "\n",
    "    path_file = path_file.replace(str(i+1), str(i+2)) \n",
    "    path_label = path_label.replace(str(i+1), str(i+2))\n",
    "    \n",
    "    # Print updated data dimensions\n",
    "    print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Final data shapes\")\n",
    "print(\"Data: \", dataset.shape)\n",
    "print(\"Labels: \", labels.shape)\n",
    "print(\"List: \", len(data_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'> Label each row using 3 classes separatly for each trial </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_period = 1000 # rows considered after first labeled row, duration in label dataset is 313 \n",
    "# label the rows for each trial separately because row_nr starts from 0 for each trial\n",
    "trials_labels = []\n",
    "\n",
    "for data in data_list:\n",
    "    \n",
    "    train = data[0]\n",
    "    label = data[1]\n",
    "    \n",
    "    label_results = [0] * len(train) # make it work for every file\n",
    "\n",
    "    # Extract the labels for each instance\n",
    "    for index, row in label.iterrows():\n",
    "        label = row[0]\n",
    "        row_nr = row[1]\n",
    "        duration = row[2]\n",
    "        if(label == 769 or label == 770 or label == 771 ):\n",
    "            duration = time_period\n",
    "        for i in range(duration):\n",
    "            current_label = label_results[row_nr + i - 1]\n",
    "            if label == 769 or label == 770 or label == 771 :\n",
    "                label_results[row_nr + i - 1] = label\n",
    "            elif current_label != 769 and current_label != 770 and current_label != 771 :\n",
    "                label_results[row_nr + i - 1] = 1\n",
    "\n",
    "    # Merge the data\n",
    "    se = pd.Series(label_results)\n",
    "    train['label'] = se.values\n",
    "    trials_labels.append(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data:  (6005911, 26)\n"
     ]
    }
   ],
   "source": [
    "# merge all trials together to one dataframe \n",
    "merge_trials = pd.DataFrame(trials_labels[0])\n",
    "for i in range(8):\n",
    "    merge_trials = merge_trials.append(trials_labels[i+1])\n",
    "\n",
    "train = merge_trials\n",
    "print(\"Data: \", train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "769 0x0301 Cue onset left (class 1) <br>\n",
    "770 0x0302 Cue onset right (class 2) <br>\n",
    "771 0x0303 Cue onset foot (class 3) <br>\n",
    "772 0x0304 Cue onset tongue (class 4) <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size:  (1944000, 27)\n"
     ]
    }
   ],
   "source": [
    "# eliminate other classes from data\n",
    "df = train[(train.label==769) | (train.label==770) | (train.label==771) ]\n",
    "df = df.reset_index() \n",
    "print(\"data size: \" , df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1944000, 23)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove extra electrodes\n",
    "df = df.drop(['index', 22, 23, 24], axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral Analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1) doing FFT for whole matrix \n",
    "#fft_df = pd.DataFrame(np.abs(np.fft.fft(df.iloc[:,0:22])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1944, 22, 501)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO this needs to be reviewed if numbers are correct \n",
    "# because in the end it gives the same number of instances for all file as for 1 file\n",
    "\n",
    "# spectral analyses\n",
    "last_index = 0\n",
    "label_vector = [] # train labels\n",
    "fft_array_rows = [] # train data prepared\n",
    "#print(df.shape)\n",
    "\n",
    "for i in range(int(len(df)/time_period)):\n",
    "    current_matrix = df[last_index:last_index+time_period]\n",
    "    #print(current_matrix.shape)\n",
    "    \n",
    "    fft_array_columns = []\n",
    "    label_vector.append(current_matrix[\"label\"][last_index])\n",
    "    last_index = last_index + time_period\n",
    "\n",
    "    # 2) OR doing FFT for single row \n",
    "    for i in range(22):\n",
    "        fft_array_columns.append(np.fft.rfft(current_matrix[i]))\n",
    "        \n",
    "    fft_array_rows.append(fft_array_columns)\n",
    "    \n",
    "    #3) OR FFT for whole matrix of each trial \n",
    "    #fft_array_rows.append(np.fft.rfft(current_matrix,22)[0])\n",
    "\n",
    "        \n",
    "df_abs = np.abs(fft_array_rows) \n",
    "df_abs.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# joining last two dimensions\n",
    "new_df_abs = []\n",
    "for i in range(len(df_abs)):\n",
    "    l = []\n",
    "    for j in range(len(df_abs[i])):\n",
    "        for n in range(len(df_abs[i][j])):\n",
    "            l.append(df_abs[i][j][n])\n",
    "    new_df_abs.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2) OR 3) create DataFrame for single FFT\n",
    "tt = pd.DataFrame(new_df_abs)\n",
    "tt['label'] = label_vector\n",
    "tt = tt.dropna()\n",
    "tt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_x = pd.DataFrame(tt.iloc[:,0:tt.shape[1] - 1]) # Instances of the data\n",
    "data_y = pd.DataFrame(tt.iloc[:,tt.shape[1] - 1]) # Labels of the data\n",
    "\n",
    "# split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_x, data_y, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marielle model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "class clf_sev:\n",
    "  \n",
    "    def train(self, data, num_subjects):\n",
    "        j = 0\n",
    "        self.models = []\n",
    "        for i in range(num_subjects):\n",
    "            data_x = pd.DataFrame(data.iloc[j:j+288,0:11022]) # Instances of the data\n",
    "            data_y = pd.DataFrame(data.iloc[j:j+288,11022]) # Labels of the data\n",
    "            j = j + 288\n",
    "            X_train, X_test, y_train, y_test = train_test_split(data_x, data_y, test_size=0.2, random_state=0)\n",
    "\n",
    "            # Train the model\n",
    "\n",
    "            model = LinearDiscriminantAnalysis()\n",
    "            model.fit(X_train, y_train)\n",
    "            self.models.append(model)\n",
    "                      \n",
    "    def predict(self, X_test):\n",
    "\n",
    "        pred = []\n",
    "        for model in self.models:\n",
    "            y_pred = model.predict(X_test)\n",
    "            pred.append(y_pred)\n",
    "        #get most frequent one\n",
    "        freq = []\n",
    "        for i in range(len(X_test)):\n",
    "            for j in range(9):\n",
    "                list = []\n",
    "                list.append(pred[j][i])\n",
    "            freq.append(max(list,key=list.count))\n",
    "\n",
    "        return freq\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\natiami\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\natiami\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\natiami\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 11022)) while a minimum of 2 is required by LinearDiscriminantAnalysis.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-da15901d9323>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf_sev\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-29-3f11d8717728>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, data, num_subjects)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearDiscriminantAnalysis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[0mTarget\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m         \"\"\"\n\u001b[1;32m--> 429\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    571\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[0;32m    572\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 573\u001b[1;33m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[0;32m    574\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    460\u001b[0m                              \u001b[1;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m                              % (n_samples, shape_repr, ensure_min_samples,\n\u001b[1;32m--> 462\u001b[1;33m                                 context))\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_features\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 11022)) while a minimum of 2 is required by LinearDiscriminantAnalysis."
     ]
    }
   ],
   "source": [
    "clf = clf_sev()\n",
    "clf.train(tt,9)\n",
    "pred = clf.predict(X_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_quality(model):\n",
    "    # Accuracy of prediction on train data\n",
    "    y_pred = model.predict(X_train)\n",
    "    print(\"Accuracy on train data \", 100*accuracy_score(y_train, y_pred))\n",
    "    \n",
    "    # Accuracy of prediction on test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"Accuracy on test data \", 100*accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    print()\n",
    "    # Precision  on test data\n",
    "    df = {'Precision': precision_score(y_test.values, y_pred, average=None)}\n",
    "    df = pd.DataFrame(data=df)\n",
    "    print(df)\n",
    "    \n",
    "    print()\n",
    "    conf_mat = confusion_matrix(y_test, y_pred, labels=[770,769,771])\n",
    "    print(\"Confusion matrix: \")\n",
    "    print(pd.DataFrame(conf_mat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\natiami\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\natiami\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis(n_components=10, priors=None, shrinkage=None,\n",
       "              solver='svd', store_covariance=False, tol=0.4)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the LDA model\n",
    "lda = LinearDiscriminantAnalysis(n_components=10, priors=None, shrinkage=None,\n",
    "              solver='svd', store_covariance=False, tol=0.4)\n",
    "lda.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train data  83.8436482085\n",
      "Accuracy on test data  35.4166666667\n",
      "\n",
      "   Precision\n",
      "0   0.364407\n",
      "1   0.338583\n",
      "2   0.359712\n",
      "\n",
      "Confusion matrix: \n",
      "    0   1   2\n",
      "0  43  41  46\n",
      "1  44  43  43\n",
      "2  40  34  50\n"
     ]
    }
   ],
   "source": [
    "check_quality(lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\natiami\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=40, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the KNN model\n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights=\"uniform\", algorithm=\"auto\", leaf_size=40, p=2, \n",
    "                           metric=\"minkowski\", metric_params=None, n_jobs=1)\n",
    "knn.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train data  55.3745928339\n",
      "Accuracy on test data  38.0208333333\n",
      "\n",
      "   Precision\n",
      "0   0.365385\n",
      "1   0.387931\n",
      "2   0.416667\n",
      "\n",
      "Confusion matrix: \n",
      "    0   1   2\n",
      "0  45  66  19\n",
      "1  38  76  16\n",
      "2  33  66  25\n"
     ]
    }
   ],
   "source": [
    "check_quality(knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\natiami\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=2, gamma=5, kernel='poly',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.25, verbose=False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svm = svm.SVC(C=1.0, kernel=\"poly\", degree=2, gamma=5, coef0=0.0, shrinking=True, probability=True, tol=0.25, \n",
    "              cache_size=200, class_weight=None, verbose=False, max_iter=-1, random_state=None)\n",
    "svm.fit(X_train, y_train)  \n",
    "svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train data  100.0\n",
      "Accuracy on test data  44.2708333333\n",
      "\n",
      "   Precision\n",
      "0   0.410853\n",
      "1   0.439655\n",
      "2   0.474820\n",
      "\n",
      "Confusion matrix: \n",
      "    0   1   2\n",
      "0  51  46  33\n",
      "1  37  53  40\n",
      "2  28  30  66\n"
     ]
    }
   ],
   "source": [
    "check_quality(svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\natiami\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train data  37.9153094463\n",
      "Accuracy on test data  33.0729166667\n",
      "\n",
      "   Precision\n",
      "0   0.328520\n",
      "1   0.392857\n",
      "2   0.316456\n",
      "\n",
      "Confusion matrix: \n",
      "    0   1   2\n",
      "0  11  97  22\n",
      "1   7  91  32\n",
      "2  10  89  25\n"
     ]
    }
   ],
   "source": [
    "check_quality(nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=10,\n",
       "            max_features=10, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=10,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "dt = tree.DecisionTreeClassifier(criterion='entropy',  max_depth = 10, max_features=10, min_samples_split=10)\n",
    "dt = dt.fit(X_train, y_train)\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train data  59.2182410423\n",
      "Accuracy on test data  33.59375\n",
      "\n",
      "   Precision\n",
      "0   0.324074\n",
      "1   0.312500\n",
      "2   0.386364\n",
      "\n",
      "Confusion matrix: \n",
      "    0   1   2\n",
      "0  25  78  27\n",
      "1  33  70  27\n",
      "2  22  68  34\n"
     ]
    }
   ],
   "source": [
    "check_quality(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Ensemble Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\natiami\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
       "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
       "         n_estimators=5, n_jobs=1, oob_score=False, random_state=0,\n",
       "         verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc = BaggingClassifier(random_state=0, bootstrap=True, n_estimators=5)\n",
    "bc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train data  93.2247557003\n",
      "Accuracy on test data  37.5\n",
      "\n",
      "   Precision\n",
      "0   0.356021\n",
      "1   0.434343\n",
      "2   0.351064\n",
      "\n",
      "Confusion matrix: \n",
      "    0   1   2\n",
      "0  43  54  33\n",
      "1  34  68  28\n",
      "2  22  69  33\n"
     ]
    }
   ],
   "source": [
    "check_quality(bc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\natiami\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=50, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=0, bootstrap=True, n_estimators=50, max_features=50)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train data  100.0\n",
      "Accuracy on test data  30.2083333333\n",
      "\n",
      "   Precision\n",
      "0   0.273973\n",
      "1   0.321739\n",
      "2   0.317073\n",
      "\n",
      "Confusion matrix: \n",
      "    0   1   2\n",
      "0  37  56  37\n",
      "1  43  40  47\n",
      "2  35  50  39\n"
     ]
    }
   ],
   "source": [
    "check_quality(rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\natiami\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=5, random_state=0)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost = AdaBoostClassifier(random_state=0, n_estimators=5)\n",
    "adaboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train data  43.9087947883\n",
      "Accuracy on test data  35.4166666667\n",
      "\n",
      "   Precision\n",
      "0   0.438356\n",
      "1   0.333333\n",
      "2   0.335938\n",
      "\n",
      "Confusion matrix: \n",
      "    0   1   2\n",
      "0  61  24  45\n",
      "1  58  32  40\n",
      "2  64  17  43\n"
     ]
    }
   ],
   "source": [
    "check_quality(adaboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'> Train model for each subject separately and agregate</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
